[{"content":"Introduction Cache hierarchies are everywhere‚Äîfrom L1/L2/L3 on your CPU to Redis clusters backing your microservices. But the way we organize and manage these tiers has fundamentally transformed over the past three decades. What started as simple in-memory buffers has evolved into a sophisticated science of eviction policies, write-through strategies, and predictive prefetching.\nThis post explores why caches are structured the way they are, how eviction strategies have improved, and what the actual data tells us about their effectiveness over time.\nThe Cache Problem At its core, caching solves a fundamental asymmetry: access speeds vary wildly. Reading from memory takes ~100 nanoseconds. Reading from disk takes ~10 milliseconds. That\u0026rsquo;s a 100,000x difference. A cache\u0026rsquo;s job is to minimize trips to slower storage by keeping hot data nearby.\nBut caches have finite capacity. When full, you must decide what to evict. Get this wrong, and your hit rate craters. Get it right, and you can hide most of the latency penalty.\nHistorical Context: Why Hierarchies Exist Early computers (1980s-early 1990s) had flat memory architectures. A single level of cache‚Äîor none at all. As CPU speeds increased while DRAM latency barely budged, the problem became acute. A CPU could execute instructions faster than memory could feed them data.\nIntel\u0026rsquo;s solution, pioneered with the i486 (1989), was multi-tier caching:\nL1 Cache: Tiny (8-32KB), extremely fast (2-4 cycles), physically close to execution units L2 Cache: Larger (256KB-1MB), slower (10-20 cycles), shared or per-core L3 Cache: Larger still (4-16MB), even slower (40-75 cycles), shared across cores The insight was hierarchical: if you can\u0026rsquo;t fit everything in L1, overflow to L2. If you can\u0026rsquo;t fit in L2, overflow to L3. This architecture minimizes the probability of hitting the slowest tier (main memory).\nBy the late 1990s, this pattern was so effective that it became the de facto standard for all levels of caching‚Äîfrom CPU caches to database buffers to distributed caches like memcached.\nEviction Policies: The Core Problem With multiple tiers, the critical question is: which data stays, which gets evicted?\nLeast Recently Used (LRU) LRU was the dominant policy for decades. The intuition is simple: if you haven\u0026rsquo;t used something recently, you won\u0026rsquo;t need it soon. Remove the least recently accessed item when capacity is exceeded.\nAccess pattern: A, B, C, A, B, D (cache size = 3) Step 1: [A] Step 2: [A, B] Step 3: [A, B, C] Step 4: [B, C, A] (A accessed, moves to end) Step 5: [C, A, B] (B accessed, moves to end) Step 6: [A, B, D] (C evicted, D added) LRU is simple to implement and works reasonably well for temporal locality (programs access recently-used data again soon). However, it has a critical weakness: sequential scans. If you\u0026rsquo;re scanning a large array, you evict the entire cache\u0026rsquo;s contents without using them twice.\nLeast Frequently Used (LFU) LFU tracks how many times each item was accessed, evicting the least-accessed. It captures true \u0026ldquo;popularity\u0026rdquo; better than LRU.\nThe trade-off? It\u0026rsquo;s expensive. Maintaining frequency counters requires additional bookkeeping. More importantly, it\u0026rsquo;s inflexible to access pattern changes. An item accessed 100 times an hour ago is treated the same as an item accessed 100 times just now.\nVariants and Hybrids By the 2000s, the research community had developed sophisticated variants:\nClock: LRU approximation using a circular buffer and a single \u0026ldquo;hand\u0026rdquo; pointer. Much faster than true LRU. W-TinyLFU: Hybrid combining recency (LRU) and frequency (LFU). Used in Caffeine cache (Java). ARC (Adaptive Replacement Cache): Learns whether your workload benefits more from recency or frequency, adjusts dynamically. Modern caches like Redis (v4.0+) support multiple policies, letting you choose based on your access patterns.\nCache Tier Interactions: A Sequence Diagram How do these tiers actually work together? Here\u0026rsquo;s a typical read miss cascading through the hierarchy:\nCPU Core L1 Cache L2 Cache L3 Cache Main Memory | | | | | | Read 0x1234 (miss) | | | | |------- req -------------\u0026gt;| | | | | | Check 0x1234 (miss) | | | | |------- req --------\u0026gt;| | | | | | Check 0x1234 (miss) | | | | |------- req --------\u0026gt;| | | | | | Check 0x1234 (hit) | | | | |\u0026lt;----- data ---------| | | |\u0026lt;----- data ---------| | | | | [Evict if full] | | | |\u0026lt;----- data ---------| | | | | [Evict if full] | | | |\u0026lt;----- data --------------| | | | | [Execute with data] | | | | When the CPU needs data, it checks L1. Missing, it requests L2. Missing there too, L3. Finally main memory. On the way back, the data fills each tier. If a tier is full, an eviction policy determines what gets removed.\nThe key insight: lower tiers must have space. If L1 evicts to L2 but L2 is full, L2 must first evict to L3. This cascading effect is why eviction policy matters‚Äîpoor choices at one level propagate upward.\nWrite-Through vs. Write-Back How do we handle writes? Two main strategies emerged:\nWrite-Through Every write goes immediately to the next level down:\nCPU writes to L1 ‚Üí L1 writes to L2 ‚Üí L2 writes to L3 ‚Üí L3 writes to main memory Advantage: Data is always consistent. Disadvantage: Write latency is high (you wait for main memory).\nWrite-Back Write to the cache, mark it as \u0026ldquo;dirty,\u0026rdquo; and only write down when that cache line is evicted:\nCPU writes to L1 ‚Üí L1 marks as dirty (done immediately) [Later, when L1 needs space] L1 evicts dirty line ‚Üí writes to L2 Advantage: Write latency is much lower. Disadvantage: Complexity and risk of data loss if the cache fails before writeback.\nModern systems mostly use write-back with careful handling of dirty bits and write-back queues.\nPrefetching: Getting Ahead of Misses By the 2010s, architectures added speculative prefetching. If you access A[i], the hardware speculatively prefetches A[i+1], A[i+2], etc.\nThis reduces cache misses for predictable access patterns but adds complexity and can waste cache space on mispredictions.\nQuantifying Improvements: 30 Years of Data Let me put numbers to this evolution. Here\u0026rsquo;s what the research shows about hit rates:\nL1 Cache Hit Rates (1995 vs. 2025)\n1995 (Pentium): ~90% typical hit rate, ~80% worst-case 2005 (Core 2): ~92% typical hit rate, ~85% worst-case 2015 (Broadwell): ~94% typical hit rate, ~88% worst-case 2025 (Sapphire Rapids): ~95% typical hit rate, ~90% worst-case The improvements are incremental but consistent. Modern CPUs benefit from:\nSmarter prefetching algorithms (now ML-assisted in latest Intel/AMD chips) Larger L3 caches relative to working set sizes Better eviction policies (Clock approximation vs. naive LRU) L3 Cache Eviction Rates (Misses per 1000 Accesses)\nYear LRU (Naive) Clock ARC Optimal 1995 ~150 ~140 N/A ~120 2000 ~130 ~115 ~110 ~95 2005 ~110 ~95 ~90 ~75 2010 ~95 ~80 ~75 ~60 2015 ~75 ~60 ~55 ~40 2020 ~60 ~45 ~40 ~25 2025 ~50 ~35 ~30 ~18 (These are synthetic workload averages; real numbers vary by application.)\nWhy the steady decline? Several factors:\nBetter eviction policies: We moved from naive LRU to adaptive, learning-based policies. Larger caches: L3 cache sizes have grown 10x since 1995, making \u0026ldquo;everything fits\u0026rdquo; more common. Prefetching: Modern hardware prefetches so accurately that cache misses are often hidden. Compiler improvements: Compilers now optimize for cache behavior (loop tiling, data layout). Distributed Caches: The Pattern Scales The same principles that work for CPU caches apply to distributed systems. Redis, memcached, and distributed caching layers all use variants of these eviction policies.\nWhen you configure Redis with maxmemory-policy allkeys-lru, you\u0026rsquo;re using the same principle: keep recently-accessed data, evict the rest.\nThe challenge in distributed caching is higher complexity:\nMultiple servers must coordinate eviction Network latency means prefetching is less effective Workloads are often less predictable Yet the core insight remains: a well-tuned eviction policy reduces misses, increases throughput, and lowers latency.\nThe Practical Takeaway If you\u0026rsquo;re building a system with caching, here\u0026rsquo;s what 30 years of research tells us:\nLRU is good, but variants like Clock or ARC are better. If your framework supports it, use them. Understand your access patterns. Sequential scans need different policies than random access. Measure hit rates. You can\u0026rsquo;t optimize what you don\u0026rsquo;t measure. Profile your actual cache behavior. Prefetching matters. For predictable workloads, it can reduce eviction pressure by 20-30%. Size your caches conservatively. A cache that\u0026rsquo;s 80% full is more stable than one constantly at capacity. The evolution of caching isn\u0026rsquo;t flashy‚Äîno breakthroughs, just steady incremental improvements. But collectively, those improvements mean modern systems need far fewer trips to slow storage than systems from 20 years ago.\nThat\u0026rsquo;s the power of doing one thing well.\n","permalink":"https://ryanjhamby.github.io/blog/cache-eviction-improvements/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eCache hierarchies are everywhere‚Äîfrom L1/L2/L3 on your CPU to Redis clusters backing your microservices. But the way we organize and manage these tiers has fundamentally transformed over the past three decades. What started as simple in-memory buffers has evolved into a sophisticated science of eviction policies, write-through strategies, and predictive prefetching.\u003c/p\u003e\n\u003cp\u003eThis post explores why caches are structured the way they are, how eviction strategies have improved, and what the actual data tells us about their effectiveness over time.\u003c/p\u003e","title":"Cache Eviction: 30 Years of Improvements"},{"content":"I\u0026rsquo;m a Software Engineer II at Amazon Web Services working on payment compliance and infrastructure for AWS Marketplace.\nWhat I Do I build resilient, scalable systems that solve complex problems. My focus is on the intersection of cloud architecture, system design, and fintech‚Äîwhere reliability, compliance, and performance are non-negotiable.\nBackground I graduated from the University of Michigan with a B.S.E. in Computer Science (Magna Cum Laude) and have spent my career building production systems at AWS. I\u0026rsquo;ve worked on distributed systems processing millions of requests per day, led infrastructure redesigns that unlocked hundreds of millions in annual revenue, and mentored engineers on system design principles.\nInterests Fintech \u0026amp; Payments - Building the financial infrastructure of tomorrow Distributed Systems - Designing systems that scale and remain consistent Cloud Architecture - Leveraging AWS to solve business-critical problems System Design - Breaking down complex problems into elegant solutions Trading \u0026amp; Quant Systems - Algorithmic systems and quantitative analysis Outside of Work I\u0026rsquo;m passionate about continuous learning. I\u0026rsquo;ve built multiple mobile apps (iOS/Android), explored quantitative trading systems, and contributed to open-source projects. I also run the M-HEAL Solar Fridge project at the University of Michigan, which develops thermoelectric systems to improve vaccine storage in developing countries.\nFeel free to reach out on LinkedIn, GitHub, or email me at hambyr@umich.edu.\n","permalink":"https://ryanjhamby.github.io/about/","summary":"\u003cp\u003eI\u0026rsquo;m a Software Engineer II at Amazon Web Services working on payment compliance and infrastructure for AWS Marketplace.\u003c/p\u003e\n\u003ch2 id=\"what-i-do\"\u003eWhat I Do\u003c/h2\u003e\n\u003cp\u003eI build resilient, scalable systems that solve complex problems. My focus is on the intersection of cloud architecture, system design, and fintech‚Äîwhere reliability, compliance, and performance are non-negotiable.\u003c/p\u003e\n\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI graduated from the University of Michigan with a B.S.E. in Computer Science (Magna Cum Laude) and have spent my career building production systems at AWS. I\u0026rsquo;ve worked on distributed systems processing millions of requests per day, led infrastructure redesigns that unlocked hundreds of millions in annual revenue, and mentored engineers on system design principles.\u003c/p\u003e","title":"About"},{"content":"Get in Touch I\u0026rsquo;d love to hear from you. Reach out with any questions, opportunities, or just to chat about trading systems, fintech, or software engineering.\nEmail: ryan.j.hamby@gmail.com\nYou can also find me on:\nLinkedIn GitHub ","permalink":"https://ryanjhamby.github.io/contact/","summary":"\u003ch2 id=\"get-in-touch\"\u003eGet in Touch\u003c/h2\u003e\n\u003cp\u003eI\u0026rsquo;d love to hear from you. Reach out with any questions, opportunities, or just to chat about trading systems, fintech, or software engineering.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eEmail:\u003c/strong\u003e \u003ca href=\"mailto:ryan.j.hamby@gmail.com\"\u003eryan.j.hamby@gmail.com\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eYou can also find me on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://linkedin.com/in/ryanjhamby\"\u003eLinkedIn\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/RyanJHamby\"\u003eGitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Contact"},{"content":"Education University of Michigan B.S.E. in Computer Science, Minor in Electrical Engineering | Dec 2022\nGPA: 3.65 / 4.00, Magna Cum Laude\nLeadership \u0026amp; Involvement:\nVP of M-HEAL (250-member Global Health Engineering Club) M-Racing (Formula SAE Racing) - Member 3D Printing Club - Member Certifications üìï AWS Certified Solutions Architect Associate (2024) üìò AWS Certified Developer (2025) Technical Skills Languages: Java, Python, TypeScript (production) | C++ (projects) | SQL (proficient) | Rust (learning)\nInfrastructure \u0026amp; DevOps: Linux, Redis, Kafka, PostgreSQL, gRPC, Docker, Terraform, AWS (EC2, Lambda, DynamoDB, RDS, ECS, S3, Step Functions)\nML/Data Engineering: PyTorch, TensorFlow, AWS SageMaker, Pandas, NumPy\nFrontend: React, Node.js, Flutter, iOS (Swift), Android (Kotlin), TailwindCSS, Figma\nOperations: 112 days on-call maintaining 99.95% uptime across 5 services processing 2M+ requests/day\n","permalink":"https://ryanjhamby.github.io/education/","summary":"\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ch3 id=\"university-of-michigan\"\u003eUniversity of Michigan\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eB.S.E. in Computer Science, Minor in Electrical Engineering | Dec 2022\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eGPA: 3.65 / 4.00, Magna Cum Laude\u003c/p\u003e\n\u003cp\u003eLeadership \u0026amp; Involvement:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eVP of M-HEAL (250-member Global Health Engineering Club)\u003c/li\u003e\n\u003cli\u003eM-Racing (Formula SAE Racing) - Member\u003c/li\u003e\n\u003cli\u003e3D Printing Club - Member\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"certifications\"\u003eCertifications\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eüìï AWS Certified Solutions Architect Associate (2024)\u003c/li\u003e\n\u003cli\u003eüìò AWS Certified Developer (2025)\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"technical-skills\"\u003eTechnical Skills\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages:\u003c/strong\u003e Java, Python, TypeScript (production) | C++ (projects) | SQL (proficient) | Rust (learning)\u003c/p\u003e","title":"Education \u0026 Skills"},{"content":"Amazon Web Services - Software Development Engineer II AWS Marketplace, Payment Compliance Team | Dec 2024 - Present | New York, NY\nKey Achievements Architected dual-partition multi-tenant infrastructure enabling AWS Marketplace expansion into 27-country sovereign cloud, supporting $200M+ in new international GMV annually Led pre-launch compliance review identifying 7 regulatory gaps (GDPR, PCI-DSS, KYC) across EU/APAC that would have blocked $100M+ annual revenue stream Eliminated $2M+ annual reconciliation errors by building event-driven sync service maintaining consistency across 3 payment workflows with exactly-once delivery of 50K+ daily updates Reduced Japan seller onboarding from 6 days to 2 days through KYC workflow redesign with Step Functions retry optimization and automated validation, unlocking $10M+ in blocked inventory Amazon Web Services - Software Development Engineer AWS IoT SiteWise / AWS Marketplace | Mar 2023 - Nov 2024 | Boston, MA / New York, NY\nHighlights Redesigned AWS IoT SiteWise asset hierarchy reducing customer onboarding by 40% and enabling 10K+ concurrent industrial IoT devices per account Eliminated UUID collision vulnerabilities affecting 3 high-traffic APIs by implementing token-based idempotency with 3-hour expiration windows, preventing duplicate resource creation in distributed systems processing 1M+ requests/day Featured Projects AWS IoT SiteWise Bulk Import/Export User-Defined Unique Identifiers ","permalink":"https://ryanjhamby.github.io/experience/","summary":"\u003ch2 id=\"amazon-web-services---software-development-engineer-ii\"\u003eAmazon Web Services - Software Development Engineer II\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAWS Marketplace, Payment Compliance Team | Dec 2024 - Present | New York, NY\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Amazon Logo\" loading=\"lazy\" src=\"/images/amazon.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"key-achievements\"\u003eKey Achievements\u003c/h3\u003e\n\u003cdiv class=\"achievement\"\u003e\nArchitected dual-partition multi-tenant infrastructure enabling AWS Marketplace expansion into 27-country sovereign cloud, supporting \u003cspan class=\"metric\"\u003e$200M+ in new international GMV annually\u003c/span\u003e\n\u003c/div\u003e\n\u003cdiv class=\"achievement\"\u003e\nLed pre-launch compliance review identifying \u003cspan class=\"metric\"\u003e7 regulatory gaps\u003c/span\u003e (GDPR, PCI-DSS, KYC) across EU/APAC that would have blocked \u003cspan class=\"metric\"\u003e$100M+ annual revenue stream\u003c/span\u003e\n\u003c/div\u003e\n\u003cdiv class=\"achievement\"\u003e\nEliminated \u003cspan class=\"metric\"\u003e$2M+ annual reconciliation errors\u003c/span\u003e by building event-driven sync service maintaining consistency across 3 payment workflows with exactly-once delivery of 50K+ daily updates\n\u003c/div\u003e\n\u003cdiv class=\"achievement\"\u003e\nReduced Japan seller onboarding from \u003cspan class=\"metric\"\u003e6 days to 2 days\u003c/span\u003e through KYC workflow redesign with Step Functions retry optimization and automated validation, unlocking \u003cspan class=\"metric\"\u003e$10M+ in blocked inventory\u003c/span\u003e\n\u003c/div\u003e\n\u003chr\u003e\n\u003ch2 id=\"amazon-web-services---software-development-engineer\"\u003eAmazon Web Services - Software Development Engineer\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAWS IoT SiteWise / AWS Marketplace | Mar 2023 - Nov 2024 | Boston, MA / New York, NY\u003c/strong\u003e\u003c/p\u003e","title":"Experience"},{"content":"Java4Java ‚Äî iOS/Android Anki-like LeetCode Learning Platform May 2025 - Present | 100+ installs\nBuilt cross-platform mobile app (Swift, Kotlin) for algorithm practice through spaced repetition. Deployed on iOS, macOS, iPad, and Android with 100+ active installs.\n‚¨áÔ∏è Download on the App Store\nKey Features:\nImplemented SM-2 spaced repetition improving retention by 30%; personalized recommendations based on proficiency and mastery patterns Engineered offline-first sync with conflict-free queue reconciliation using CRDTs, achieving 99.5% data consistency across devices during intermittent connectivity Monetized via AdMob optimizing fill rates to 85%+ through waterfall bidding and A/B tested placements, generating sustainable revenue while maintaining UX RhythmIQ | Music Streaming App with Personalized Playlists Jan 2025 - Present\nüìä View GitHub Repository\nOptimized data flow for low-latency music recommendation, modular Java architecture with AWS Lambda, and real-time context detection via sensor data.\nDesign Documents:\nüìÑ RhythmIQ Low-Level Design Document üìÑ RhythmIQ High-Level Design Document This project features a recommendation engine using collaborative filtering and content-based filtering, AWS Lambda for efficient processing, and Dagger for dependency management within Java.\nElectric Vehicle Explorer \u0026amp; Breakeven Calculator July 2023 - Aug 2023\nüåê Live Website | üíª GitHub Repo\nDeveloped a website displaying sustainable fuel vehicles to gain experience with TypeScript and React. Features include debounced searching, sorting, filtering, and pagination.\nM-HEAL Solar Fridge Project Team Lead \u0026amp; Electrical Sub Team Lead | Jan 2019 - Present\nSolar Fridge is a student-run project team at Michigan Health Engineered for All Lives. Our 15-member team iterates through insulation and thermoelectric refrigeration designs to cool vaccine coolers.\nKey Achievements:\nImproved the amount of time that dorm fridges can sustain a 2-8¬∞C range by over 800% Created a touchscreen LCD digital data logger that displays current and previous vaccine temperatures Designed PCB to condense thermocouple leads and implemented Arduino code driver üîó M-HEAL Solar Fridge Home Page\nConcept \u0026amp; Implementation: M-HEAL Leadership Internal Vice President | March 2021 - April 2022\nManaged and oversaw progress of 12 independent project teams covering global health problems. Organized design reviews, facilitated recruiting, met with external partners, and worked closely with the 14-person board to direct the organization.\nPhone-Free Driving Device Owner | Sep 2019 - Dec 2019\nDesigned an automotive safety device that restricts phone access unless the car is at a complete stop, using AutoCAD, Arduino, servo motor, GPS module, and ultrasonic sensor.\nAchievement: 2nd Place in GM Additive Manufacturing Design Competition\nSmartCycle Machine Learning Recycling App May 2020 - Sept 2021\nDeveloped an iOS app with ML-powered recycling bin detection to encourage recycling through point rewards. Utilized IBM Cloud Machine Learning and Apple CoreML for image classification trained on thousands of recyclable items.\nTrained ML algorithm to discriminate against reusable water bottles to prevent cheating Integrated Swift frontend with CoreML models for real-time detection Backed user data using Google Firebase for persistent storage ","permalink":"https://ryanjhamby.github.io/hobby-projects/","summary":"\u003ch2 id=\"java4java--iosandroid-anki-like-leetcode-learning-platform\"\u003eJava4Java ‚Äî iOS/Android Anki-like LeetCode Learning Platform\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eMay 2025 - Present | 100+ installs\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"project-showcase\"\u003e\n\u003cp\u003eBuilt cross-platform mobile app (Swift, Kotlin) for algorithm practice through spaced repetition. Deployed on iOS, macOS, iPad, and Android with 100+ active installs.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://apps.apple.com/us/app/java4java/id6754247227\"\u003e‚¨áÔ∏è Download on the App Store\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eKey Features:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eImplemented SM-2 spaced repetition improving retention by 30%; personalized recommendations based on proficiency and mastery patterns\u003c/li\u003e\n\u003cli\u003eEngineered offline-first sync with conflict-free queue reconciliation using CRDTs, achieving 99.5% data consistency across devices during intermittent connectivity\u003c/li\u003e\n\u003cli\u003eMonetized via AdMob optimizing fill rates to 85%+ through waterfall bidding and A/B tested placements, generating sustainable revenue while maintaining UX\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"rhythmiq--music-streaming-app-with-personalized-playlists\"\u003eRhythmIQ | Music Streaming App with Personalized Playlists\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eJan 2025 - Present\u003c/strong\u003e\u003c/p\u003e","title":"Hobby Projects"},{"content":"Low-Latency Order Book Engine Sep 2025 - Dec 2025\nüìä View GitHub Repository\nMinimal, high-performance order book engine in C++ designed to explore the foundations of low-latency trading systems. Includes nanosecond-level order matcher skeleton, lock-free queues, thread-local memory pools, and automated benchmarking on AWS EC2 spot instances.\nBuilt C++ order book engine with lock-free queues, thread-local memory pools, and inlined matching‚Äîbenchmarked at 1M+ orders with average match latency under 1 microsecond Automated EC2 spot benchmarking with cloud-init for reproducible, low-cost latency profiling Architecture Order Matching Core:\nMinimal memory allocation design for sub-microsecond latency Inlined matching logic for CPU cache efficiency Lock-free queue skeleton for order ingestion Thread-local memory pools to reduce contention Benchmarking Pipeline:\nSimulates 1M+ orders with alternating buy/sell sides Measures average microseconds per match Reproducible results on local machine or EC2 Separation of Concerns:\nOrder ingestion (queue) ‚Üí matching engine ‚Üí latency measurement Decoupled architecture mirrors real exchange pipelines Local Development Build \u0026amp; Run:\ncd orderbook-engine chmod +x scripts/build_and_run_benchmark.sh ./scripts/build_and_run_benchmark.sh This script:\nCleans and creates fresh build directory Configures with CMake and builds with parallel jobs Runs validation executable Executes latency benchmark ‚Üí build/benchmark_results.txt Unit Tests:\nchmod +x scripts/run_tests.sh ./scripts/run_tests.sh Test coverage:\nOrder creation, type validation, comparison operations Order addition, matching, stress testing (1000 orders) Lock-free queue push/pop operations Thread-local memory pool allocation (2000 stress allocations) Cloud Benchmarking Automated EC2 Spot Execution:\nchmod +x scripts/run_benchmark.sh ./scripts/run_benchmark.sh Process:\nLaunches EC2 spot instance with specified AMI/instance type Cloud-init installs dependencies (build-essential, cmake, git, perf) Clones repository and executes benchmark Logs results to /home/ubuntu/benchmark_results.txt Automatically shuts down instance after completion Benefits: Repeatable benchmarking at low cost with cloud infrastructure consistency.\nDesign Insights Sub-microsecond latency goal: Minimal allocations, cache-aware layouts, inlined hot paths Lock-free architecture: Eliminates mutex contention in order ingestion pipeline EC2 spot automation: Reduces operational overhead while maintaining reproducibility Optimization roadmap: SIMD vectorization for price matching NUMA-aware memory allocation for multi-threaded workloads Order cancellations and partial fill simulation Latency spike detection and metrics logging Intelligent Stock Screener Oct 2025 - Dec 2025\nüìä View GitHub Repository\nFully automated stock screening system scanning 3,800+ US stocks daily using Mark Minervini\u0026rsquo;s Trend Template methodology. Identifies high-conviction buy/sell signals via phase-based trend classification, relative strength momentum, and fundamental quality filters.\nAutomated daily scans of 3,800+ stocks with 74% API reduction via Git-based fundamental caching and GitHub Actions automation Phase-based classification identifying Phase 2 uptrend breakouts passing 7 of 8 Minervini criteria (50\u003e150\u003e200 SMA alignment, relative strength ‚â•70, volume confirmation) Risk-managed position management with max 10% risk, min 2:1 R:R ratio, automated stop-loss trailing, and tax-aware filtering for long-term positions Core Features Phase-Based Trend Classification:\nPhase 1 (Base): Consolidation after decline Phase 2 (Uptrend): Confirmed uptrend with 50\u0026gt;150\u0026gt;200 SMA alignment ‚Äî BUY ZONE Phase 3 (Distribution): Topping pattern with weakening momentum Phase 4 (Downtrend): Declining trend ‚Äî AVOID Volatility Contraction Pattern (VCP):\nIdentifies price consolidation before explosive breakout Formula: Range_i = ((High_i - Low_i) / Close_i) √ó 100 VCP_Score = (‚àë Contractions / Total_Periods) √ó Trend_Quality Example: 13 contractions (6.5% ‚Üí 5.8% ‚Üí 7.6% ‚Üí 6.0%) with 54/100 quality score indicates imminent breakout Intelligent Market Regime Filtering:\nOnly generates buy signals when SPY in Phase 1/2 with ‚â•15% of stocks in Phase 2 Avoids low-probability trades in declining markets Sell signals always generated (can exit any market) Smart Caching Strategy:\nFundamentals stored in Git repository as JSON with metadata Earnings season (6 weeks): refresh if \u0026gt;7 days old Normal periods: refresh if \u0026gt;90 days old Result: 74% fewer API calls, 15-20 min faster scans Sample Output üìä View Sample Scan Output (Jan 9, 2026) OPTIMIZED FULL MARKET SCAN - ALL US STOCKS Scan Date: 2026-01-09 Generated: 2026-01-09 14:04:49 SCANNING STATISTICS Total Universe: 3,819 stocks Analyzed: 1,188 stocks Buy Signals: 370 | Sell Signals: 111 Error Rate: 0.26% SPY Trend: Phase 2 - Uptrend (Bullish) ‚Ä¢ 50 SMA: $678.39 (slope: 0.0563) ‚Ä¢ 200 SMA: $626.72 (slope: 0.0982) ‚Ä¢ Confidence: 85% Market Breadth (n=1,188): ‚Ä¢ Phase 1 (Base): 560 (47.1%) ‚Ä¢ Phase 2 (Uptrend): 504 (42.4%) ‚Ä¢ Phase 3 (Distribution): 1 (0.1%) ‚Ä¢ Phase 4 (Downtrend): 123 (10.4%) Market Regime: RISK-ON (Strong) ‚≠ê BUY #1: WWD | Score: 104.5/110 Phase: 2 | Entry Quality: Good | R:R: 3.2:1 Stop Loss: $299.25 ‚Ä¢ 11.1% above 50 SMA (strong breakout) ‚Ä¢ Revenue: +16.5% YoY | EPS: +64% YoY ‚Ä¢ Volume confirmation (1.17 ratio) Covariance-Based Macro Trading System Sep 2023 - Present\nüìä View GitHub Repository\nSystematic S\u0026amp;P 500 futures trading system powered by eigendecomposition of economic indicator covariance matrices. Decomposes 8√ó8 macro factor covariance to identify uncertainty regimes and size positions via macro surprise exposure.\nAchieved 1.4 Sharpe ratio over 17-year backtest at 12% max drawdown via regime-aware position sizing and macro surprise decomposition C++ factor decomposition engine (Eigen 3.4.0) processing 8 FRED indicators + VIX with AWS Lambda daily automation, computing eigendecomposition in 12ms End-to-end pipeline: FRED API ‚Üí monthly frequency alignment (downsampling/Hermite interpolation) ‚Üí spectral decomposition (Œ£ = UŒõU·µÄ) ‚Üí S3 with 180+ unit tests and 73% alignment with NBER recession dates Core Hypothesis Markets respond to unexpected economic information, not levels. Raw covariance is misleading‚Äîit captures expected relationships.\nStandard assumption: E[r_t | X_t] = Œ± + Œ≤X_t\nReality: Markets react to surprises: ŒîX_t - E_t[ŒîX_t]\nSolution: Decompose surprise covariance via PCA to identify 3-4 interpretable macro factors (growth, inflation, policy, volatility) and measure ES exposure across regimes.\n5-Stage Architecture Data Acquisition: FRED API (CPI, GDP, Unemployment, Sentiment, Fed Funds, Treasury yields) + VIX Temporal Alignment: Daily ‚Üí month-end LOCF, Quarterly ‚Üí Hermite interpolation to monthly Covariance Estimation: Œ£_ij = (1/(n-1)) ‚àë_t (X_it - XÃÑ_i)(X_jt - XÃÑ_j) Spectral Decomposition: Œ£ = UŒõU·µÄ ‚Üí First 3-4 eigenvalues capture 85-92% variance Regime Quantification: Frobenius norm ‚ÄñŒ£‚Äñ_F = ‚àö(‚àë_i,j œÉ¬≤_ij) maps to regime state Regime Classification:\nStable (‚ÄñŒ£‚Äñ_F \u0026lt; Œº - œÉ): Low uncertainty, tight co-movement Neutral (Œº - œÉ ‚â§ ‚ÄñŒ£‚Äñ_F ‚â§ Œº + œÉ): Moderate uncertainty Elevated (‚ÄñŒ£‚Äñ_F \u0026gt; Œº + œÉ): High uncertainty, factor decoupling Infrastructure AWS Stack:\nEventBridge (cron: daily 12:00 UTC) ‚Üí Lambda (512MB, 600s) ‚Üí S3 (versioned, encrypted) Lambda execution: ~4.2s average (p95: 8.7s) Native C++ binary (662 KB) with Eigen, AWS SDK, curl IaC: AWS CDK 2.x (TypeScript, dev/staging/prod) Validation:\n180+ unit tests: covariance symmetry, eigenvalue ordering, numerical stability 5+ year backtests: 73% alignment with NBER recession dates Data Inputs 8 economic indicators at mixed frequencies:\nCPI (monthly) - Inflation anchor Real GDP (quarterly) - Earnings driver Unemployment (monthly) - Labor tightness Consumer Sentiment (monthly) - Forward demand Fed Funds (monthly) - Discount rate 10Y/2Y Treasury (daily) - Yield curve VIX (daily) - Realized volatility ","permalink":"https://ryanjhamby.github.io/projects/","summary":"\u003ch2 id=\"low-latency-order-book-engine\"\u003eLow-Latency Order Book Engine\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eSep 2025 - Dec 2025\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/RyanJHamby/OrderBookEngine\"\u003eüìä View GitHub Repository\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMinimal, high-performance order book engine in C++ designed to explore the foundations of low-latency trading systems. Includes nanosecond-level order matcher skeleton, lock-free queues, thread-local memory pools, and automated benchmarking on AWS EC2 spot instances.\u003c/p\u003e\n\u003cdiv class=\"achievement\"\u003e\nBuilt C++ order book engine with lock-free queues, thread-local memory pools, and inlined matching‚Äîbenchmarked at \u003cspan class=\"metric\"\u003e1M+ orders with average match latency under 1 microsecond\u003c/span\u003e\n\u003c/div\u003e\n\u003cdiv class=\"achievement\"\u003e\nAutomated EC2 spot benchmarking with cloud-init for reproducible, low-cost latency profiling\n\u003c/div\u003e\n\u003ch3 id=\"architecture\"\u003eArchitecture\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eOrder Matching Core:\u003c/strong\u003e\u003c/p\u003e","title":"Projects"}]